{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e1cb549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "                                              0.0/7.2 MB ? eta -:--:--\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 435, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 516, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 90, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\http\\client.py\", line 463, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\http\\client.py\", line 507, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\ssl.py\", line 1242, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\ssl.py\", line 1100, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 167, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 247, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 369, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 92, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 481, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 348, in resolve\n",
      "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 206, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 297, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 162, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 231, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 308, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 438, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 483, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 165, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 106, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 147, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 573, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 538, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\contextlib.py\", line 137, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 440, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dd519c",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "595eb408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score: 0.931411623954773\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compare_notes(notes1, notes2):\n",
    "    # Load pre-trained BERT model and tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Tokenize and encode the notes\n",
    "    tokens1 = tokenizer.encode(notes1, add_special_tokens=True)\n",
    "    tokens2 = tokenizer.encode(notes2, add_special_tokens=True)\n",
    "\n",
    "    # Convert token IDs to tensors\n",
    "    input_ids1 = torch.tensor(tokens1).unsqueeze(0)\n",
    "    input_ids2 = torch.tensor(tokens2).unsqueeze(0)\n",
    "\n",
    "    # Generate embeddings using BERT model\n",
    "    with torch.no_grad():\n",
    "        outputs1 = model(input_ids1)\n",
    "        embeddings1 = outputs1.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "        outputs2 = model(input_ids2)\n",
    "        embeddings2 = outputs2.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "    # Compute cosine similarity between embeddings\n",
    "    similarity = cosine_similarity(embeddings1, embeddings2)[0][0]\n",
    "\n",
    "    return similarity\n",
    "\n",
    "# Example usage\n",
    "notes1 = \"C:\\\\Users\\\\HP\\\\Desktop\\\\New Text Document (2).txt\"\n",
    "notes2 = \"C:\\\\Users\\\\HP\\\\Desktop\\\\notes.pdf\"\n",
    "\n",
    "similarity_score = compare_notes(notes1, notes2)\n",
    "print(f\"Similarity score: {similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013c8be0",
   "metadata": {},
   "source": [
    "# TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60070075",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\HP\\\\Desktop\\\\New Text Document (2).txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4164\\394357991.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\HP\\\\Desktop\\\\New Text Document (2).txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mnotes1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\HP\\\\Desktop\\\\New Text Document (2).txt'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import PyPDF2\n",
    "\n",
    "def compare_notes(notes1, notes2):\n",
    "    # Create a TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fit and transform the notes into TF-IDF vectors\n",
    "    tfidf_matrix = vectorizer.fit_transform([notes1, notes2])\n",
    "\n",
    "    # Calculate the cosine similarity between the TF-IDF vectors\n",
    "    similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
    "\n",
    "    return similarity\n",
    "\n",
    "with open(\"C:\\\\Users\\\\HP\\\\Desktop\\\\New Text Document (2).txt\", 'r', encoding='utf-8') as file:\n",
    "    notes1 = file.read()\n",
    "  \n",
    "with open(\"C:\\\\Users\\\\HP\\\\Desktop\\\\notes.pdf\", 'rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    notes2 = \"\"\n",
    "    for page in reader.pages:\n",
    "        notes2 = page.extract_text()\n",
    "\n",
    "similarity_score = compare_notes(notes1, notes2)\n",
    "print(f\"Similarity score: {similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486df402",
   "metadata": {},
   "source": [
    "# UI TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ffca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import PyPDF2\n",
    "\n",
    "def compare_notes(notes1, notes2):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    tfidf_matrix = vectorizer.fit_transform([notes1, notes2])\n",
    "\n",
    "    similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
    "\n",
    "    return similarity\n",
    "\n",
    "def open_text_file():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Text Files\", \"*.txt\")])\n",
    "    if file_path:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        text_entry.delete(\"1.0\", tk.END)\n",
    "        text_entry.insert(tk.END, text)\n",
    "\n",
    "def open_pdf_file():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"PDF Files\", \"*.pdf\")])\n",
    "    if file_path:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()\n",
    "        compare_entry.delete(\"1.0\", tk.END)\n",
    "        compare_entry.insert(tk.END, text)\n",
    "\n",
    "def compare():\n",
    "    notes1 = text_entry.get(\"1.0\", tk.END)\n",
    "    notes2 = compare_entry.get(\"1.0\", tk.END)\n",
    "    similarity_score = compare_notes(notes1, notes2)\n",
    "    similarity_label.config(text=f\"Similarity score: {similarity_score:.2f}\")\n",
    "\n",
    "# Create the main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Notes Comparison\")\n",
    "window.geometry(\"500x400\")\n",
    "\n",
    "\n",
    "style = ttk.Style()\n",
    "style.configure(\"TLabel\", foreground=\"#333\", font=(\"Arial\", 12))\n",
    "style.configure(\"TButton\", font=(\"Arial\", 12))\n",
    "style.configure(\"TText\", font=(\"Arial\", 12))\n",
    "\n",
    "# First Set of Notes\n",
    "text_label = ttk.Label(window, text=\"First Set of Notes:\")\n",
    "text_label.pack()\n",
    "\n",
    "text_entry = tk.Text(window, height=5)\n",
    "text_entry.pack(pady=5)\n",
    "\n",
    "open_text_button = ttk.Button(window, text=\"Open Text File\", command=open_text_file)\n",
    "open_text_button.pack()\n",
    "\n",
    "# Second Set of Notes\n",
    "compare_label = ttk.Label(window, text=\"Second Set of Notes:\")\n",
    "compare_label.pack()\n",
    "\n",
    "compare_entry = tk.Text(window, height=5)\n",
    "compare_entry.pack(pady=5)\n",
    "\n",
    "open_pdf_button = ttk.Button(window, text=\"Open PDF File\", command=open_pdf_file)\n",
    "open_pdf_button.pack()\n",
    "\n",
    "# Compare Button\n",
    "compare_button = ttk.Button(window, text=\"Compare Notes\", command=compare)\n",
    "compare_button.pack(pady=10)\n",
    "\n",
    "# Similarity Score\n",
    "similarity_label = ttk.Label(window, text=\"Similarity score: \")\n",
    "similarity_label.pack()\n",
    "\n",
    "# Run the main event loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d24c47",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60cf7769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk import download \n",
    "download('stopwords')\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93858822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk\n",
    "import PyPDF2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into individual words\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Convert to lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    # Remove stopwords and punctuation\n",
    "    stopwords_set = set(stopwords.words(\"english\"))\n",
    "    tokens = [token for token in tokens if token.isalnum() and token not in stopwords_set]\n",
    "    # Join the tokens back into a single string\n",
    "    preprocessed_text = \" \".join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "def compare_answers(student_answer, ideal_answer):\n",
    "    # Preprocess the student and ideal answers\n",
    "    notes1 = preprocess_text(student_answer)\n",
    "    notes2 = preprocess_text(ideal_answer)\n",
    "\n",
    "    # Create a TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    # Fit the vectorizer on the preprocessed answers\n",
    "    vectors = vectorizer.fit_transform([notes1, notes2])\n",
    "\n",
    "    # Compute the cosine similarity between the vectors\n",
    "    similarity = cosine_similarity(vectors[0], vectors[1])[0][0]\n",
    "    return similarity\n",
    "\n",
    "def open_text_file():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Text Files\", \"*.txt\")])\n",
    "    if file_path:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        text_entry.delete(\"1.0\", tk.END)\n",
    "        text_entry.insert(tk.END, text)\n",
    "\n",
    "def open_pdf_file():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"PDF Files\", \"*.pdf\")])\n",
    "    if file_path:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()\n",
    "        compare_entry.delete(\"1.0\", tk.END)\n",
    "        compare_entry.insert(tk.END, text)\n",
    "        \n",
    "def compare():\n",
    "    notes1 = text_entry.get(\"1.0\", tk.END)\n",
    "    notes2 = compare_entry.get(\"1.0\", tk.END)\n",
    "    similarity_score = compare_notes(notes1, notes2)\n",
    "    similarity_label.config(text=f\"Similarity score: {similarity_score:.2f}\")    \n",
    "    \n",
    "    \n",
    "# Create the main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Notes Comparison\")\n",
    "window.geometry(\"700x400\")\n",
    "\n",
    "\n",
    "style = ttk.Style()\n",
    "style.configure(\"TLabel\", foreground=\"#333\", font=(\"Arial\", 12))\n",
    "style.configure(\"TButton\", font=(\"Arial\", 12))\n",
    "style.configure(\"TText\", font=(\"Arial\", 12))\n",
    "\n",
    "# First Set of Notes\n",
    "text_label = ttk.Label(window, text=\"First Set of Notes:\")\n",
    "text_label.pack()\n",
    "\n",
    "text_entry = tk.Text(window, height=5)\n",
    "text_entry.pack(pady=5)\n",
    "\n",
    "open_text_button = ttk.Button(window, text=\"Open Text File\", command=open_text_file)\n",
    "open_text_button.pack()\n",
    "\n",
    "# Second Set of Notes\n",
    "compare_label = ttk.Label(window, text=\"Second Set of Notes:\")\n",
    "compare_label.pack()\n",
    "\n",
    "compare_entry = tk.Text(window, height=5)\n",
    "compare_entry.pack(pady=5)\n",
    "\n",
    "open_pdf_button = ttk.Button(window, text=\"Open PDF File\", command=open_pdf_file)\n",
    "open_pdf_button.pack()\n",
    "\n",
    "# Compare Button\n",
    "compare_button = ttk.Button(window, text=\"Compare Notes\", command=compare)\n",
    "compare_button.pack(pady=10)\n",
    "\n",
    "# Similarity Score\n",
    "similarity_label = ttk.Label(window, text=\"Similarity score: \")\n",
    "similarity_label.pack()\n",
    "\n",
    "# Run the main event loop\n",
    "window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1879828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
